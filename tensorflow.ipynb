{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Iris Data Set\n",
    "This notebook contains solutions to the TensorFlow problem sheet. This problem sheet uses the famous iris data set. This data set contains data regarding three related species, or classes, of Iris flowers. There are 50 samples per class making a total of 150 samples. Each sample consists of five variables, they are the sepal length in cm, sepal width in cm, petal length in cm, petal width in cm and and the class, in that order. The three classes are Iris Setosa, Iris Versicolour and Iris Virginica. The full desciption of the data set can be found here. This Jupyter notebook will involve building a model in TensorFlow to classify an Iris flower based on the sepal and petal length and width. Before starting, import any libraries that might be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For loading the data set.\n",
    "import csv\n",
    "\n",
    "# Efficiently deals with numerical multi-dimensional arrays.\n",
    "import numpy as np\n",
    "\n",
    "# Build a neural network to classify iris flowers.\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "The first step is to download the iris data set a file called iris.csv in the data folder and then load the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['4.9', '3.0', '1.4', '0.2', 'Iris-setosa'],\n",
       " ['4.7', '3.2', '1.3', '0.2', 'Iris-setosa'],\n",
       " ['4.6', '3.1', '1.5', '0.2', 'Iris-setosa'],\n",
       " ['5.0', '3.6', '1.4', '0.2', 'Iris-setosa'],\n",
       " ['5.4', '3.9', '1.7', '0.4', 'Iris-setosa'],\n",
       " ['4.6', '3.4', '1.4', '0.3', 'Iris-setosa'],\n",
       " ['5.0', '3.4', '1.5', '0.2', 'Iris-setosa'],\n",
       " ['4.4', '2.9', '1.4', '0.2', 'Iris-setosa'],\n",
       " ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa'],\n",
       " ['5.4', '3.7', '1.5', '0.2', 'Iris-setosa'],\n",
       " ['4.8', '3.4', '1.6', '0.2', 'Iris-setosa'],\n",
       " ['4.8', '3.0', '1.4', '0.1', 'Iris-setosa'],\n",
       " ['4.3', '3.0', '1.1', '0.1', 'Iris-setosa'],\n",
       " ['5.8', '4.0', '1.2', '0.2', 'Iris-setosa'],\n",
       " ['5.7', '4.4', '1.5', '0.4', 'Iris-setosa'],\n",
       " ['5.4', '3.9', '1.3', '0.4', 'Iris-setosa'],\n",
       " ['5.1', '3.5', '1.4', '0.3', 'Iris-setosa'],\n",
       " ['5.7', '3.8', '1.7', '0.3', 'Iris-setosa'],\n",
       " ['5.1', '3.8', '1.5', '0.3', 'Iris-setosa'],\n",
       " ['5.4', '3.4', '1.7', '0.2', 'Iris-setosa'],\n",
       " ['5.1', '3.7', '1.5', '0.4', 'Iris-setosa'],\n",
       " ['4.6', '3.6', '1.0', '0.2', 'Iris-setosa'],\n",
       " ['5.1', '3.3', '1.7', '0.5', 'Iris-setosa'],\n",
       " ['4.8', '3.4', '1.9', '0.2', 'Iris-setosa'],\n",
       " ['5.0', '3.0', '1.6', '0.2', 'Iris-setosa'],\n",
       " ['5.0', '3.4', '1.6', '0.4', 'Iris-setosa'],\n",
       " ['5.2', '3.5', '1.5', '0.2', 'Iris-setosa'],\n",
       " ['5.2', '3.4', '1.4', '0.2', 'Iris-setosa'],\n",
       " ['4.7', '3.2', '1.6', '0.2', 'Iris-setosa'],\n",
       " ['4.8', '3.1', '1.6', '0.2', 'Iris-setosa'],\n",
       " ['5.4', '3.4', '1.5', '0.4', 'Iris-setosa'],\n",
       " ['5.2', '4.1', '1.5', '0.1', 'Iris-setosa'],\n",
       " ['5.5', '4.2', '1.4', '0.2', 'Iris-setosa'],\n",
       " ['4.9', '3.1', '1.5', '0.2', 'Iris-setosa'],\n",
       " ['5.0', '3.2', '1.2', '0.2', 'Iris-setosa'],\n",
       " ['5.5', '3.5', '1.3', '0.2', 'Iris-setosa'],\n",
       " ['4.9', '3.6', '1.4', '0.1', 'Iris-setosa'],\n",
       " ['4.4', '3.0', '1.3', '0.2', 'Iris-setosa'],\n",
       " ['5.1', '3.4', '1.5', '0.2', 'Iris-setosa'],\n",
       " ['5.0', '3.5', '1.3', '0.3', 'Iris-setosa'],\n",
       " ['4.5', '2.3', '1.3', '0.3', 'Iris-setosa'],\n",
       " ['4.4', '3.2', '1.3', '0.2', 'Iris-setosa'],\n",
       " ['5.0', '3.5', '1.6', '0.6', 'Iris-setosa'],\n",
       " ['5.1', '3.8', '1.9', '0.4', 'Iris-setosa'],\n",
       " ['4.8', '3.0', '1.4', '0.3', 'Iris-setosa'],\n",
       " ['5.1', '3.8', '1.6', '0.2', 'Iris-setosa'],\n",
       " ['4.6', '3.2', '1.4', '0.2', 'Iris-setosa'],\n",
       " ['5.3', '3.7', '1.5', '0.2', 'Iris-setosa'],\n",
       " ['5.0', '3.3', '1.4', '0.2', 'Iris-setosa'],\n",
       " ['7.0', '3.2', '4.7', '1.4', 'Iris-versicolor'],\n",
       " ['6.4', '3.2', '4.5', '1.5', 'Iris-versicolor'],\n",
       " ['6.9', '3.1', '4.9', '1.5', 'Iris-versicolor'],\n",
       " ['5.5', '2.3', '4.0', '1.3', 'Iris-versicolor'],\n",
       " ['6.5', '2.8', '4.6', '1.5', 'Iris-versicolor'],\n",
       " ['5.7', '2.8', '4.5', '1.3', 'Iris-versicolor'],\n",
       " ['6.3', '3.3', '4.7', '1.6', 'Iris-versicolor'],\n",
       " ['4.9', '2.4', '3.3', '1.0', 'Iris-versicolor'],\n",
       " ['6.6', '2.9', '4.6', '1.3', 'Iris-versicolor'],\n",
       " ['5.2', '2.7', '3.9', '1.4', 'Iris-versicolor'],\n",
       " ['5.0', '2.0', '3.5', '1.0', 'Iris-versicolor'],\n",
       " ['5.9', '3.0', '4.2', '1.5', 'Iris-versicolor'],\n",
       " ['6.0', '2.2', '4.0', '1.0', 'Iris-versicolor'],\n",
       " ['6.1', '2.9', '4.7', '1.4', 'Iris-versicolor'],\n",
       " ['5.6', '2.9', '3.6', '1.3', 'Iris-versicolor'],\n",
       " ['6.7', '3.1', '4.4', '1.4', 'Iris-versicolor'],\n",
       " ['5.6', '3.0', '4.5', '1.5', 'Iris-versicolor'],\n",
       " ['5.8', '2.7', '4.1', '1.0', 'Iris-versicolor'],\n",
       " ['6.2', '2.2', '4.5', '1.5', 'Iris-versicolor'],\n",
       " ['5.6', '2.5', '3.9', '1.1', 'Iris-versicolor'],\n",
       " ['5.9', '3.2', '4.8', '1.8', 'Iris-versicolor'],\n",
       " ['6.1', '2.8', '4.0', '1.3', 'Iris-versicolor'],\n",
       " ['6.3', '2.5', '4.9', '1.5', 'Iris-versicolor'],\n",
       " ['6.1', '2.8', '4.7', '1.2', 'Iris-versicolor'],\n",
       " ['6.4', '2.9', '4.3', '1.3', 'Iris-versicolor'],\n",
       " ['6.6', '3.0', '4.4', '1.4', 'Iris-versicolor'],\n",
       " ['6.8', '2.8', '4.8', '1.4', 'Iris-versicolor'],\n",
       " ['6.7', '3.0', '5.0', '1.7', 'Iris-versicolor'],\n",
       " ['6.0', '2.9', '4.5', '1.5', 'Iris-versicolor'],\n",
       " ['5.7', '2.6', '3.5', '1.0', 'Iris-versicolor'],\n",
       " ['5.5', '2.4', '3.8', '1.1', 'Iris-versicolor'],\n",
       " ['5.5', '2.4', '3.7', '1.0', 'Iris-versicolor'],\n",
       " ['5.8', '2.7', '3.9', '1.2', 'Iris-versicolor'],\n",
       " ['6.0', '2.7', '5.1', '1.6', 'Iris-versicolor'],\n",
       " ['5.4', '3.0', '4.5', '1.5', 'Iris-versicolor'],\n",
       " ['6.0', '3.4', '4.5', '1.6', 'Iris-versicolor'],\n",
       " ['6.7', '3.1', '4.7', '1.5', 'Iris-versicolor'],\n",
       " ['6.3', '2.3', '4.4', '1.3', 'Iris-versicolor'],\n",
       " ['5.6', '3.0', '4.1', '1.3', 'Iris-versicolor'],\n",
       " ['5.5', '2.5', '4.0', '1.3', 'Iris-versicolor'],\n",
       " ['5.5', '2.6', '4.4', '1.2', 'Iris-versicolor'],\n",
       " ['6.1', '3.0', '4.6', '1.4', 'Iris-versicolor'],\n",
       " ['5.8', '2.6', '4.0', '1.2', 'Iris-versicolor'],\n",
       " ['5.0', '2.3', '3.3', '1.0', 'Iris-versicolor'],\n",
       " ['5.6', '2.7', '4.2', '1.3', 'Iris-versicolor'],\n",
       " ['5.7', '3.0', '4.2', '1.2', 'Iris-versicolor'],\n",
       " ['5.7', '2.9', '4.2', '1.3', 'Iris-versicolor'],\n",
       " ['6.2', '2.9', '4.3', '1.3', 'Iris-versicolor'],\n",
       " ['5.1', '2.5', '3.0', '1.1', 'Iris-versicolor'],\n",
       " ['5.7', '2.8', '4.1', '1.3', 'Iris-versicolor'],\n",
       " ['6.3', '3.3', '6.0', '2.5', 'Iris-virginica'],\n",
       " ['5.8', '2.7', '5.1', '1.9', 'Iris-virginica'],\n",
       " ['7.1', '3.0', '5.9', '2.1', 'Iris-virginica'],\n",
       " ['6.3', '2.9', '5.6', '1.8', 'Iris-virginica'],\n",
       " ['6.5', '3.0', '5.8', '2.2', 'Iris-virginica'],\n",
       " ['7.6', '3.0', '6.6', '2.1', 'Iris-virginica'],\n",
       " ['4.9', '2.5', '4.5', '1.7', 'Iris-virginica'],\n",
       " ['7.3', '2.9', '6.3', '1.8', 'Iris-virginica'],\n",
       " ['6.7', '2.5', '5.8', '1.8', 'Iris-virginica'],\n",
       " ['7.2', '3.6', '6.1', '2.5', 'Iris-virginica'],\n",
       " ['6.5', '3.2', '5.1', '2.0', 'Iris-virginica'],\n",
       " ['6.4', '2.7', '5.3', '1.9', 'Iris-virginica'],\n",
       " ['6.8', '3.0', '5.5', '2.1', 'Iris-virginica'],\n",
       " ['5.7', '2.5', '5.0', '2.0', 'Iris-virginica'],\n",
       " ['5.8', '2.8', '5.1', '2.4', 'Iris-virginica'],\n",
       " ['6.4', '3.2', '5.3', '2.3', 'Iris-virginica'],\n",
       " ['6.5', '3.0', '5.5', '1.8', 'Iris-virginica'],\n",
       " ['7.7', '3.8', '6.7', '2.2', 'Iris-virginica'],\n",
       " ['7.7', '2.6', '6.9', '2.3', 'Iris-virginica'],\n",
       " ['6.0', '2.2', '5.0', '1.5', 'Iris-virginica'],\n",
       " ['6.9', '3.2', '5.7', '2.3', 'Iris-virginica'],\n",
       " ['5.6', '2.8', '4.9', '2.0', 'Iris-virginica'],\n",
       " ['7.7', '2.8', '6.7', '2.0', 'Iris-virginica'],\n",
       " ['6.3', '2.7', '4.9', '1.8', 'Iris-virginica'],\n",
       " ['6.7', '3.3', '5.7', '2.1', 'Iris-virginica'],\n",
       " ['7.2', '3.2', '6.0', '1.8', 'Iris-virginica'],\n",
       " ['6.2', '2.8', '4.8', '1.8', 'Iris-virginica'],\n",
       " ['6.1', '3.0', '4.9', '1.8', 'Iris-virginica'],\n",
       " ['6.4', '2.8', '5.6', '2.1', 'Iris-virginica'],\n",
       " ['7.2', '3.0', '5.8', '1.6', 'Iris-virginica'],\n",
       " ['7.4', '2.8', '6.1', '1.9', 'Iris-virginica'],\n",
       " ['7.9', '3.8', '6.4', '2.0', 'Iris-virginica'],\n",
       " ['6.4', '2.8', '5.6', '2.2', 'Iris-virginica'],\n",
       " ['6.3', '2.8', '5.1', '1.5', 'Iris-virginica'],\n",
       " ['6.1', '2.6', '5.6', '1.4', 'Iris-virginica'],\n",
       " ['7.7', '3.0', '6.1', '2.3', 'Iris-virginica'],\n",
       " ['6.3', '3.4', '5.6', '2.4', 'Iris-virginica'],\n",
       " ['6.4', '3.1', '5.5', '1.8', 'Iris-virginica'],\n",
       " ['6.0', '3.0', '4.8', '1.8', 'Iris-virginica'],\n",
       " ['6.9', '3.1', '5.4', '2.1', 'Iris-virginica'],\n",
       " ['6.7', '3.1', '5.6', '2.4', 'Iris-virginica'],\n",
       " ['6.9', '3.1', '5.1', '2.3', 'Iris-virginica'],\n",
       " ['5.8', '2.7', '5.1', '1.9', 'Iris-virginica'],\n",
       " ['6.8', '3.2', '5.9', '2.3', 'Iris-virginica'],\n",
       " ['6.7', '3.3', '5.7', '2.5', 'Iris-virginica'],\n",
       " ['6.7', '3.0', '5.2', '2.3', 'Iris-virginica'],\n",
       " ['6.3', '2.5', '5.0', '1.9', 'Iris-virginica'],\n",
       " ['6.5', '3.0', '5.2', '2.0', 'Iris-virginica'],\n",
       " ['6.2', '3.4', '5.4', '2.3', 'Iris-virginica'],\n",
       " ['5.9', '3.0', '5.1', '1.8', 'Iris-virginica']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = list(csv.reader(open('data/iris.csv')))[1:]\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, split this data set into inputs and outputs using NumPy. The inputs are the sepal length, sepal width, petal length and petal width which are the first four columns of data. The possible outputs are setosa, versicolor or virginica, which is the fifth column of data. The inputs are floats and the outputs are strings at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get values from the first four columns of the array.\n",
    "inputs = np.array(iris)[:,:4].astype(np.float)\n",
    "\n",
    "# Get values from the fifth column of the array.\n",
    "outputs = np.array(iris)[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want the outputs to be strings. Instead we want to categorise them using one-hot arrays so that they can be used by our model later. To achieve this we must first convert the different classes to corresponding integers. For example, setosa will become 0, versicolor will become 1 and virginica will become 2. We then convert these integers to one-hot arrays meaning setosa will be represented as [1, 0, 0], versicolor will be represented as [0, 1, 0] and virginica will be represented as [0, 0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the output strings to ints.\n",
    "outputs_vals, outputs_ints = np.unique(outputs, return_inverse=True)\n",
    "\n",
    "# Convert to one-hot array.\n",
    "# Adapte from https://stackoverflow.com/questions/38592324/one-hot-encoding-using-numpy\n",
    "targets = np.array(outputs_ints).reshape(-1)\n",
    "outputs_one_hot = np.eye(3)[targets]\n",
    "outputs_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Split the data into training and testing\n",
    "Now that the data is in the correct format, split both the input and output data sets into training and test subsets with 75 entries in each set. Before we do this however we must randomly separate the data. Otherwise all the setosa and half the versicolor classes will be in the training set and all the virginica and the other half of the versicolor classes will be in the testing set. We do this by generating an array of random indices between 0 and 149 and spliting that in half. Each array denotes the indices of the elements in the iris ata set to be used as training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get an array of random indices between 0 and 149.\n",
    "indices = np.random.permutation(len(inputs))\n",
    "\n",
    "# Split the array of random indices in half.\n",
    "train_indices, test_indices = np.array_split(indices, 2)\n",
    "\n",
    "# Use the two arrays to separate the iris data set into taining and testing data.\n",
    "inputs_train, outputs_train = inputs[train_indices], outputs_one_hot[train_indices]\n",
    "inputs_test, outputs_test = inputs[test_indices],  outputs_one_hot[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tensorflow to create model\n",
    "Use Tensorflow to create a model to predict the species of Iris from a flowers sepal width, sepal length, petal width, and petal length. The softmax regression technique is a common algorithm for solving classification problems in machine learning. It assigns the probabilities of an object being one of several different things. This techniques gives a list of values between 0 and 1 that add up to 1. The index in the list with the highest value indicates the category the model estimated the data to belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://www.tensorflow.org/get_started/mnist/beginners\n",
    "# Create a placeholder node for the input data.\n",
    "x = tf.placeholder(tf.float32, [None, 4])\n",
    "\n",
    "# Create the weight and bias as variables so that their values can be adjusted by tensorflow.\n",
    "# They are initialised as tensors full of zeros.\n",
    "W = tf.Variable(tf.zeros([4, 3]))\n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "# Implement the model using softmax.\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is ready, we can train it using the test data created earlier. A cost function is necessary in order to quantify the accuracy of the model. The lower the cost the more accurate the model will be. The cross-entropy function is a common way to calculate the cost of a model in machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The actual results from the test data.\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "# Implement the cross-entropy function.\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "# Minimize cross_entropy using the gradient descent algorithm with a learning rate of 0.5.\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a TensorFlow session and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorflow session in which the model will run and initialize the variables.\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Start by training the model 1000 times.\n",
    "for _ in range(1000):\n",
    "    sess.run(train_step, feed_dict={x: inputs_train, y_: outputs_train})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
